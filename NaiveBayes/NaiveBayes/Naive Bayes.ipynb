{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes\n",
    "\n",
    "Is a supervised classification algorithm.\n",
    "\n",
    "Before we jump into Naive Bayes let's review a few probability concepts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If A and B are two events of an experiment then\n",
    "\n",
    "1) $ 0 \\leq P(A) \\leq 1 $ likewise $ 0 \\leq P(B) \\leq 1.$\n",
    "\n",
    "2) $ P(A) + P(B) = 1.$\n",
    "\n",
    "3) $ P(A') = 1 - P(A) $ here $A'$ is the complement of A. Some use $A^{c}$ to represent complement of A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we flip a coin what are the outcomes?\n",
    "\n",
    "Flipping a fair coin is the experiment. \n",
    "\n",
    "Possible outcomes: Heads or Tails, the events are getting heads or getting tails\n",
    "\n",
    "probability of getting heads?\n",
    "\n",
    "P(heads) = number of ways of getting heads/total number of possible outcomes = 1/2 \n",
    "\n",
    "P(no heads) = P(tails) = 1 - P(heads) = 1 - 1/2 = 1/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we flip two coins then what is the probability of:\n",
    "    \n",
    "possible outcomes: HH, HT, TH, TT, number of possible outcomes is 4\n",
    "\n",
    "1) Getting two heads:\n",
    "\n",
    "P(HH) = number of ways of getting two heads/total possibilities = 1/4 = 0.25 = 25%\n",
    "\n",
    "2) One head and one tail:\n",
    "\n",
    "P(one head and one tail) = 2/4 = 1/2 = 0.5 = 50%\n",
    "\n",
    "3) At least one tail means one or more tails:\n",
    "\n",
    "P(at least one tail) = 1 - P(no tails) = 1 - P(all heads) = 1 - 1/4 = 3/4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-class activity: If you roll a six-sided die, what is the probability of:\n",
    "\n",
    "Outcomes are {1, 2, 3, 4, 5, 6}, number of outcomes is 6\n",
    "\n",
    "1) Getting a 2:\n",
    "\n",
    "\n",
    "2) Getting 3 or 5:\n",
    "\n",
    "\n",
    "3) Getting an even number:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: \n",
    "\n",
    "If we flip one coin - possible outcomes are 2.\n",
    "\n",
    "If we flip two coins - possible outcomes are $2^2 = 4.$\n",
    "\n",
    "If we roll a six-sided die - possible outcomes are 6.\n",
    "\n",
    "If we roll two six-sided dice - possible outcomes are $6^2 = 36.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rolling two six-sided dice: \n",
    "\n",
    "least sum is 2, highest sum is 12.\n",
    "\n",
    "\n",
    "sums that are divisible by 3: sum 3, sum 6, sum 9 and sum 12\n",
    "\n",
    "outcomes - (1,2)(2,1) (1,5)(5,1)(2,4)(4,2),(3,3) (3,6)(6,3)(4,5)(5,4) (6,6)\n",
    "\n",
    "total outcomes who sum is divisible by 3 is = 12\n",
    "\n",
    "P(sum that is divisible by 3) = 12/36 = 1/3\n",
    "\n",
    "\n",
    "sums that are divisible by 4: sum 4, sum 8, sum 12\n",
    "\n",
    "outcomes - (1,3)(2,2)(3,1) (2,6)(3,5)(4,4)(5,3)(6,2) (6,6)\n",
    "\n",
    "total outcomes who sum is divisible by 4 is = 9\n",
    "\n",
    "P(sum that is divisible by 4)  = 9/36 = 1/4\n",
    "\n",
    "\n",
    "only sum 12 is divisible by both 3 and 4, this can be obtained by (6,6) \n",
    "\n",
    "P(sum that is divisible by 3 and 4)  = 1/36\n",
    "\n",
    "\n",
    "P(sum that is divisible by 3 or 4) = P(sum divisible by 3) + P(sum divisible by 4) - P(sum divisible by both 3 and 4) = 12/36 + 9/36 - 1/36 = 20/36.\n",
    "\n",
    "\n",
    "sums that are divisible by 5: sum 5, sum 10\n",
    "\n",
    "outcomes -(1,4)(4,1)(2,3)(3,2) (4,6)(6,4)(5,5)\n",
    "\n",
    "sums that are divisible by 6: sum 6, sum 12\n",
    "\n",
    "outcomes -(1,5)(5,1)(2,4)(4,2)(3,3), (6,6)\n",
    "\n",
    "\n",
    "P(sum divisible by both 5 and  6) = 0/36 = 0\n",
    "\n",
    "P(sum divisble by 5 or 6) = P(sum div by 5) + P(sum div by 6) = 7/36 + 6/36 = 13/36 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-class activity: If you roll two six-sided die, what is the probability of:\n",
    "\n",
    "1) Getting two even numbers.\n",
    "\n",
    "\n",
    "\n",
    "P(2 even numbers) = 9/36 = 1/4\n",
    "\n",
    "\n",
    "2) Getting a sum of 7\n",
    "\n",
    "\n",
    "3) Getting a sum divisible by 8\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If two events are independent then\n",
    "\n",
    "$ P(A \\cap B) = P(A)*P(B).$\n",
    "\n",
    "\n",
    "Deck of 52 cards - 4 suits - hearts (red), diamonds (red), spades (black), and clubs (black). How many cards in each suit? 13 cards in each suit.\n",
    "\n",
    "What kind of cards - 2, 3, ..., 10, J, Q, K, A - 9 number cards, face cards 3, and 1 ace. \n",
    "\n",
    "We are drawing a card from a deck of 52 cards. Answer the following:\n",
    "\n",
    "P(a red card) = 26/52 = 1/2 = 50%\n",
    "\n",
    "P(a face card) = 12/52 \n",
    "\n",
    "Let's consider a few examples:\n",
    "\n",
    "1) Two cards are drawn from a deck of 52 cards with replacement. \n",
    "\n",
    "1a) What is the probability of choosing a king and then a nine?\n",
    " \n",
    "P(a king and a nine) = 4/52 * 4/52 = 1/13 * 1/13 = 1/169\n",
    "\n",
    "1b) What is the probability of choosing a number card and then a face card?\n",
    "\n",
    "P(a numbered and a face) = 36/52 * 12/52 \n",
    "\n",
    "2) A bowl contains 3 red, 4 green and 8 blue marbles. Three marbles are drawn from the bowl with replacement. What is the probability of choosing a blue, a red and a green?\n",
    "\n",
    "\n",
    "r = 3, g = 4, b = 8, total marbles are 15\n",
    "\n",
    "P(b and r and g) = 8/15 * 3/15 * 4/15 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-class activity: If you roll a die twice, what is the probability of:\n",
    "\n",
    "1) Getting a 4 on the first roll and a 3 on the second roll. \n",
    "\n",
    "\n",
    "2) Getting an even number on the first roll and a number divisible by 3 on second.\n",
    "\n",
    "\n",
    "3) Getting a sum divisible by 5 or a sum divisible by 4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional probability \n",
    "\n",
    "Conditional probability of A given B is, another way to think about this is probability of A when we know that B happened.\n",
    "    \n",
    "P(A, given B) = $ P(A|B) = \\frac{P(A \\cap B)}{P(B)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We roll a six-sided die. What is the probability of getting a 4 given that an even number occured?\n",
    "\n",
    "P(4|even) = P(4 and even)/P(even) = 1/6/3/6 = 1/6 * 6/3 = 1/3\n",
    "\n",
    "\n",
    "P(3|even) = P(3 and even)/P(even) = 0/3/6 = 0\n",
    "\n",
    "\n",
    "Conditional probability is shrinking the total outcomes of experiment.\n",
    "\n",
    "We rolled the die, we know that the outcome is an even number. \n",
    "P( 4 |got an even number) = 1/3\n",
    "\n",
    "\n",
    "P(7|odd) = 0/3/6 = 0\n",
    "\n",
    "P(6|odd) = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a few examples:\n",
    "\n",
    "1a) If you pick a card from a deck of 52 cards, then what is the probability of getting an ace given it is a diamond?\n",
    "\n",
    "straight-forward way:\n",
    "\n",
    "P(ace|diamond) = 1/13\n",
    "\n",
    "conditional probability \n",
    "\n",
    "P(Ace|Diamond) = P(Ace and Diamond)/P(Diamond) = 1/52/13/52 = 1/52 * 52/13 = 1/13 \n",
    "\n",
    "1b) If you pick a card from a deck of 52 cards, what is the probability of getting a face card given it is a red card?\n",
    "\n",
    "straight-forward way: \n",
    "\n",
    "P(face|red) = 6/26 \n",
    "\n",
    "conditional probability\n",
    "\n",
    "P(face|red) = P(face and red)/P(red) = 6/52/26/52 = 6/26 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Consider the table below. What is the probability that a person chosen at random from the below group is a teacher given that they are a female?\n",
    "\n",
    "<img src=\"conditional1.png\" width=300, height=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(teacher|female) = P(teacher and female)/P(female) = 8/100/40/100 = 8/100 * 100/40 = 8/40 = 1/5 = 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find\n",
    "\n",
    "1. P(male|teacher) ?\n",
    "\n",
    "P(male and teacher) =  12/100 \n",
    "\n",
    "P(male|teacher)  = P(male and teacher)/P(teacher) = 12/100/20/100 = 12/100 * 100/20 =  12/20 = 3/5\n",
    "\n",
    "straight forward way, P(male|teacher) = 12/20\n",
    "\n",
    "\n",
    "2. P(student|male) ? \n",
    "\n",
    "P(student and male) = 48/100 \n",
    "\n",
    "P(student|male) = P(student and male)/P(male) = 48/100/60/100 = 48/60 = 8/10 = 4/5\n",
    "\n",
    "straight forward way, P(student|male) = 48/60\n",
    "\n",
    "P(Female|male) = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In-class activity: If you roll a dice once, what is the probability of:\n",
    "\n",
    "1) Getting a 5 given that the outcome is odd. \n",
    "\n",
    "2) Getting 4 given that the outcome is odd.\n",
    "\n",
    "3) Getting 6 given that the outcome is divisible by 3. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes\n",
    "\n",
    "Is a probabilistic classifier technique.\n",
    "\n",
    "It is fast and scalable. Used for binary and for multi class classification. \n",
    "\n",
    "It assumes that every feature is unrelated to other features.\n",
    "This is the disadvantage of this model as in real life, features might not be unrelated to each other. \n",
    "\n",
    "\n",
    "Where is Naive Bayes used:\n",
    "\n",
    "1) Text classification\n",
    "\n",
    "2) Recommendation system\n",
    "\n",
    "3) Weather forecasting and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes formula\n",
    "\n",
    "<img src=\"bayes1.png\" width = 300, height=200>\n",
    "\n",
    "\n",
    "References:\n",
    "https://www.machinelearningplus.com/predictive-modeling/how-naive-bayes-algorithm-works-with-example-and-full-code/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(Y|X) = P(Y and X)/P(X) by using conditional probability\n",
    "\n",
    "multiply both sides by P(X)\n",
    "\n",
    "P(Y|X) P(X) = P(Y and X)  - eq (1)\n",
    "\n",
    "\n",
    "P(X|Y) = P(X and Y)/P(Y)\n",
    "\n",
    "if we multiply both sides by P(Y)\n",
    "\n",
    "P(X|Y) P(Y) = P(X and Y)  - eq (2)\n",
    "\n",
    "\n",
    "since P(X and Y) = P(Y and X), we can equate the left hand sides in equations (1) and (2)\n",
    "\n",
    "P(Y|X) P(X) = P(X|Y) P(Y)\n",
    "\n",
    "divide both sides by P(X) will give us the Bayes rule\n",
    "\n",
    "P(Y|X) = P(X|Y) * P(Y) /P(X)\n",
    "\n",
    "posterior = (likelihood * prior)/evidence\n",
    "\n",
    "\n",
    "P(X|Y) = likelihood\n",
    "\n",
    "P(Y) = prior\n",
    "\n",
    "P(X) = evidence\n",
    "\n",
    "P(Y|X) = posterior = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the golf data set.\n",
    "\n",
    "<img src=\"golf.png\">\n",
    "\n",
    "Let's create a likelihood table\n",
    "\n",
    "<img src=\"likelihood2.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to check the claim: Players will play if the weather is Rainy. \n",
    "\n",
    "method 1: using conditional probability\n",
    "\n",
    "P(y|rainy) = P(y and rainy)/P(rainy) = 3/14/5/14 = 3/5 \n",
    "\n",
    "method 1b: \n",
    "\n",
    "P(y|rainy) = 3/5 \n",
    "\n",
    "method 2: Bayes rule\n",
    "\n",
    "P(y|rainy) = $\\frac{P(rainy | yes) * P(yes)}{P(rainy)}$ = (3/9 * 9/14) / 5/14 = 3/14/5/14 = 3/5\n",
    " \n",
    "Based on P(y|rainy) should we support the claim or reject the claim? \n",
    "\n",
    "Conclusion:  Since P(y|rainy) is 60%, we can support the claim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-class activity: Using the above table can you compute the probability for the following:\n",
    "\n",
    "1) Claim: Players will not play when the weather is overcast.\n",
    "\n",
    "2) Claim: Players will play when the weather is sunny.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "#Load dataset\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
      "       [4.9, 3. , 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.3, 0.2],\n",
      "       [4.6, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.6, 1.4, 0.2],\n",
      "       [5.4, 3.9, 1.7, 0.4],\n",
      "       [4.6, 3.4, 1.4, 0.3],\n",
      "       [5. , 3.4, 1.5, 0.2],\n",
      "       [4.4, 2.9, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.1],\n",
      "       [5.4, 3.7, 1.5, 0.2],\n",
      "       [4.8, 3.4, 1.6, 0.2],\n",
      "       [4.8, 3. , 1.4, 0.1],\n",
      "       [4.3, 3. , 1.1, 0.1],\n",
      "       [5.8, 4. , 1.2, 0.2],\n",
      "       [5.7, 4.4, 1.5, 0.4],\n",
      "       [5.4, 3.9, 1.3, 0.4],\n",
      "       [5.1, 3.5, 1.4, 0.3],\n",
      "       [5.7, 3.8, 1.7, 0.3],\n",
      "       [5.1, 3.8, 1.5, 0.3],\n",
      "       [5.4, 3.4, 1.7, 0.2],\n",
      "       [5.1, 3.7, 1.5, 0.4],\n",
      "       [4.6, 3.6, 1. , 0.2],\n",
      "       [5.1, 3.3, 1.7, 0.5],\n",
      "       [4.8, 3.4, 1.9, 0.2],\n",
      "       [5. , 3. , 1.6, 0.2],\n",
      "       [5. , 3.4, 1.6, 0.4],\n",
      "       [5.2, 3.5, 1.5, 0.2],\n",
      "       [5.2, 3.4, 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.6, 0.2],\n",
      "       [4.8, 3.1, 1.6, 0.2],\n",
      "       [5.4, 3.4, 1.5, 0.4],\n",
      "       [5.2, 4.1, 1.5, 0.1],\n",
      "       [5.5, 4.2, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.2, 1.2, 0.2],\n",
      "       [5.5, 3.5, 1.3, 0.2],\n",
      "       [4.9, 3.6, 1.4, 0.1],\n",
      "       [4.4, 3. , 1.3, 0.2],\n",
      "       [5.1, 3.4, 1.5, 0.2],\n",
      "       [5. , 3.5, 1.3, 0.3],\n",
      "       [4.5, 2.3, 1.3, 0.3],\n",
      "       [4.4, 3.2, 1.3, 0.2],\n",
      "       [5. , 3.5, 1.6, 0.6],\n",
      "       [5.1, 3.8, 1.9, 0.4],\n",
      "       [4.8, 3. , 1.4, 0.3],\n",
      "       [5.1, 3.8, 1.6, 0.2],\n",
      "       [4.6, 3.2, 1.4, 0.2],\n",
      "       [5.3, 3.7, 1.5, 0.2],\n",
      "       [5. , 3.3, 1.4, 0.2],\n",
      "       [7. , 3.2, 4.7, 1.4],\n",
      "       [6.4, 3.2, 4.5, 1.5],\n",
      "       [6.9, 3.1, 4.9, 1.5],\n",
      "       [5.5, 2.3, 4. , 1.3],\n",
      "       [6.5, 2.8, 4.6, 1.5],\n",
      "       [5.7, 2.8, 4.5, 1.3],\n",
      "       [6.3, 3.3, 4.7, 1.6],\n",
      "       [4.9, 2.4, 3.3, 1. ],\n",
      "       [6.6, 2.9, 4.6, 1.3],\n",
      "       [5.2, 2.7, 3.9, 1.4],\n",
      "       [5. , 2. , 3.5, 1. ],\n",
      "       [5.9, 3. , 4.2, 1.5],\n",
      "       [6. , 2.2, 4. , 1. ],\n",
      "       [6.1, 2.9, 4.7, 1.4],\n",
      "       [5.6, 2.9, 3.6, 1.3],\n",
      "       [6.7, 3.1, 4.4, 1.4],\n",
      "       [5.6, 3. , 4.5, 1.5],\n",
      "       [5.8, 2.7, 4.1, 1. ],\n",
      "       [6.2, 2.2, 4.5, 1.5],\n",
      "       [5.6, 2.5, 3.9, 1.1],\n",
      "       [5.9, 3.2, 4.8, 1.8],\n",
      "       [6.1, 2.8, 4. , 1.3],\n",
      "       [6.3, 2.5, 4.9, 1.5],\n",
      "       [6.1, 2.8, 4.7, 1.2],\n",
      "       [6.4, 2.9, 4.3, 1.3],\n",
      "       [6.6, 3. , 4.4, 1.4],\n",
      "       [6.8, 2.8, 4.8, 1.4],\n",
      "       [6.7, 3. , 5. , 1.7],\n",
      "       [6. , 2.9, 4.5, 1.5],\n",
      "       [5.7, 2.6, 3.5, 1. ],\n",
      "       [5.5, 2.4, 3.8, 1.1],\n",
      "       [5.5, 2.4, 3.7, 1. ],\n",
      "       [5.8, 2.7, 3.9, 1.2],\n",
      "       [6. , 2.7, 5.1, 1.6],\n",
      "       [5.4, 3. , 4.5, 1.5],\n",
      "       [6. , 3.4, 4.5, 1.6],\n",
      "       [6.7, 3.1, 4.7, 1.5],\n",
      "       [6.3, 2.3, 4.4, 1.3],\n",
      "       [5.6, 3. , 4.1, 1.3],\n",
      "       [5.5, 2.5, 4. , 1.3],\n",
      "       [5.5, 2.6, 4.4, 1.2],\n",
      "       [6.1, 3. , 4.6, 1.4],\n",
      "       [5.8, 2.6, 4. , 1.2],\n",
      "       [5. , 2.3, 3.3, 1. ],\n",
      "       [5.6, 2.7, 4.2, 1.3],\n",
      "       [5.7, 3. , 4.2, 1.2],\n",
      "       [5.7, 2.9, 4.2, 1.3],\n",
      "       [6.2, 2.9, 4.3, 1.3],\n",
      "       [5.1, 2.5, 3. , 1.1],\n",
      "       [5.7, 2.8, 4.1, 1.3],\n",
      "       [6.3, 3.3, 6. , 2.5],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [7.1, 3. , 5.9, 2.1],\n",
      "       [6.3, 2.9, 5.6, 1.8],\n",
      "       [6.5, 3. , 5.8, 2.2],\n",
      "       [7.6, 3. , 6.6, 2.1],\n",
      "       [4.9, 2.5, 4.5, 1.7],\n",
      "       [7.3, 2.9, 6.3, 1.8],\n",
      "       [6.7, 2.5, 5.8, 1.8],\n",
      "       [7.2, 3.6, 6.1, 2.5],\n",
      "       [6.5, 3.2, 5.1, 2. ],\n",
      "       [6.4, 2.7, 5.3, 1.9],\n",
      "       [6.8, 3. , 5.5, 2.1],\n",
      "       [5.7, 2.5, 5. , 2. ],\n",
      "       [5.8, 2.8, 5.1, 2.4],\n",
      "       [6.4, 3.2, 5.3, 2.3],\n",
      "       [6.5, 3. , 5.5, 1.8],\n",
      "       [7.7, 3.8, 6.7, 2.2],\n",
      "       [7.7, 2.6, 6.9, 2.3],\n",
      "       [6. , 2.2, 5. , 1.5],\n",
      "       [6.9, 3.2, 5.7, 2.3],\n",
      "       [5.6, 2.8, 4.9, 2. ],\n",
      "       [7.7, 2.8, 6.7, 2. ],\n",
      "       [6.3, 2.7, 4.9, 1.8],\n",
      "       [6.7, 3.3, 5.7, 2.1],\n",
      "       [7.2, 3.2, 6. , 1.8],\n",
      "       [6.2, 2.8, 4.8, 1.8],\n",
      "       [6.1, 3. , 4.9, 1.8],\n",
      "       [6.4, 2.8, 5.6, 2.1],\n",
      "       [7.2, 3. , 5.8, 1.6],\n",
      "       [7.4, 2.8, 6.1, 1.9],\n",
      "       [7.9, 3.8, 6.4, 2. ],\n",
      "       [6.4, 2.8, 5.6, 2.2],\n",
      "       [6.3, 2.8, 5.1, 1.5],\n",
      "       [6.1, 2.6, 5.6, 1.4],\n",
      "       [7.7, 3. , 6.1, 2.3],\n",
      "       [6.3, 3.4, 5.6, 2.4],\n",
      "       [6.4, 3.1, 5.5, 1.8],\n",
      "       [6. , 3. , 4.8, 1.8],\n",
      "       [6.9, 3.1, 5.4, 2.1],\n",
      "       [6.7, 3.1, 5.6, 2.4],\n",
      "       [6.9, 3.1, 5.1, 2.3],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [6.8, 3.2, 5.9, 2.3],\n",
      "       [6.7, 3.3, 5.7, 2.5],\n",
      "       [6.7, 3. , 5.2, 2.3],\n",
      "       [6.3, 2.5, 5. , 1.9],\n",
      "       [6.5, 3. , 5.2, 2. ],\n",
      "       [6.2, 3.4, 5.4, 2.3],\n",
      "       [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'frame': None, 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': 'C:\\\\Users\\\\sridevi\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}\n"
     ]
    }
   ],
   "source": [
    "print(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n",
      "['DESCR', 'data', 'feature_names', 'filename', 'frame', 'target', 'target_names']\n"
     ]
    }
   ],
   "source": [
    "print(type(iris))\n",
    "print(dir(iris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame(iris.data) \n",
    "df_target = pd.DataFrame(iris.target)\n",
    "df = pd.concat([df_data, df_target], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3  0\n",
      "0  5.1  3.5  1.4  0.2  0\n",
      "1  4.9  3.0  1.4  0.2  0\n",
      "2  4.7  3.2  1.3  0.2  0\n",
      "3  4.6  3.1  1.5  0.2  0\n",
      "4  5.0  3.6  1.4  0.2  0\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Create a Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "gnb.fit(x_train, y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = gnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In-class activity: use GaussianNB on Titanic dataset and find the accuracy.\n",
    "\n",
    "We already have preprocessed pickle file for Titanic dataset, use that and create a data frame that pickle file\n",
    "\"\"\"\n",
    "\n",
    "# Use these features: \"Age\", \"Gender\", \"family_size\", \"Embarked\" (\"Fare\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Use these features: \"Age\", \"Gender\", \"family_size\", \"Embarked\", \"Fare\" \n",
    "\n",
    "import pickle\n",
    "\n",
    "# Use these features: \"Age\", \"Gender\", \"family_size\", \"Embarked\", \"Fare\" \n",
    "\n",
    "with open('titanic_dataframe.pk', 'rb') as f:\n",
    "    unpickled = pickle.load(f)\n",
    "    \n",
    "    \n",
    "dft = pd.DataFrame(unpickled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directly use Pandas read_pickle()\n",
    "\n",
    "# dft = pd.read_pickle(\"titanic_dataframe.pk\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
