{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines - is a model that can do both classification and \n",
    "regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"svm1.png\" width=300, height=200>\n",
    "\n",
    "References: https://commons.wikimedia.org/wiki/File:SVM_Example_of_Hyperplanes.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at another example\n",
    "\n",
    "<img src=\"svm2.png\" width=300, height=200>\n",
    "\n",
    "https://commons.wikimedia.org/wiki/File:SVM_margin.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vectors are the points that lie close to the decision boundary. \n",
    "\n",
    "The dataset will comprise of $(x_i, y_i)$ where $y_i$ is either 1 or -1 \n",
    "that indicates the class that $x_i$ belongs.\n",
    "\n",
    "Our goal is to find a hyperplane that separates the two classes with maximum margin. This hyperplane can be represented by \n",
    "$\\vec{w}\\vec{x} - \\vec{b} = 0.$\n",
    "\n",
    "Using the training dataset, we compute $\\vec{w}$ and $\\vec{b}.$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any point that lies on or above \n",
    "\n",
    "$\\vec{w}\\vec{x} - \\vec{b} = 1$ will be classified as class 1 \n",
    "and any point thay lies on or below\n",
    "\n",
    "$\\vec{w}\\vec{x} - \\vec{b} = -1$ will be classified as \n",
    "class 2.\n",
    "\n",
    "The distance between the two hyperplanes is $\\frac{2}{||\\vec{w}||},$ we want to maximize this which is same as minimizing $||\\vec{w}||.$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Hard-margin, we are very particular about the margin. No data points can lie within the margin. So hard-margins are narrow.\n",
    "\n",
    "In Soft-margin, data points can lie within the margin. Soft-margins are wide. \n",
    "\n",
    "The loss function for SVM is defined by\n",
    "\n",
    "$max(0, 1-y_i(\\vec{w}.\\vec{x_i} - b))$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://archive.ics.uci.edu/ml/datasets/banknote+authentication\n",
    "\n",
    "df = pd.read_csv(\"bill_authentication.csv\")\n",
    "df1 = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1372, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variance</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Curtosis</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variance  Skewness  Curtosis  Entropy  Class\n",
       "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
       "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
       "2   3.86600   -2.6383    1.9242  0.10645      0\n",
       "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
       "4   0.32924   -4.4552    4.5718 -0.98880      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Class\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important Links to understand skewness, curtosis (kurtosis), entropy\n",
    "\n",
    "https://www.mathsisfun.com/data/skewness.html\n",
    "\n",
    "https://www.statology.org/can-kurtosis-be-negative/\n",
    "    \n",
    "https://towardsdatascience.com/entropy-is-a-measure-of-uncertainty-e2c000301c2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc = df.drop('Class', axis=1)\n",
    "yc = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xc_train, xc_test, yc_train, yc_test = train_test_split(xc, yc, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[148   1]\n",
      " [  1 125]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       149\n",
      "           1       0.99      0.99      0.99       126\n",
      "\n",
      "    accuracy                           0.99       275\n",
      "   macro avg       0.99      0.99      0.99       275\n",
      "weighted avg       0.99      0.99      0.99       275\n",
      "\n",
      "(1097, 4)\n",
      "(1097,)\n",
      "Accuracy: 0.9927272727272727\n"
     ]
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='linear') # creating an object\n",
    "svclassifier.fit(xc_train, yc_train) # fiting the data to the model\n",
    "\n",
    "yc_pred = svclassifier.predict(xc_test)\n",
    "\n",
    "print(confusion_matrix(yc_test,yc_pred))\n",
    "print(classification_report(yc_test,yc_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(xc_train.shape)\n",
    "print(yc_train.shape)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(yc_test, yc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[145   0]\n",
      " [  0 130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       145\n",
      "           1       1.00      1.00      1.00       130\n",
      "\n",
      "    accuracy                           1.00       275\n",
      "   macro avg       1.00      1.00      1.00       275\n",
      "weighted avg       1.00      1.00      1.00       275\n",
      "\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# building a SVC with kernel = \"rbf\"\n",
    "\n",
    "svc2 = SVC() # creating an object\n",
    "svc2.fit(xc_train, yc_train) # fiting the data to the model\n",
    "\n",
    "yc_pred = svc2.predict(xc_test)\n",
    "\n",
    "print(confusion_matrix(yc_test,yc_pred))\n",
    "print(classification_report(yc_test,yc_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(yc_test, yc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[140   5]\n",
      " [  0 130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       145\n",
      "           1       0.96      1.00      0.98       130\n",
      "\n",
      "    accuracy                           0.98       275\n",
      "   macro avg       0.98      0.98      0.98       275\n",
      "weighted avg       0.98      0.98      0.98       275\n",
      "\n",
      "Accuracy: 0.9818181818181818\n"
     ]
    }
   ],
   "source": [
    "# building a SVC with kernel = \"polynomial\" with degree 3\n",
    "\n",
    "\n",
    "svc3 = SVC(kernel=\"poly\", degree=3) # creating an object\n",
    "svc3.fit(xc_train, yc_train) # fiting the data to the model\n",
    "\n",
    "yc_pred = svc3.predict(xc_test)\n",
    "\n",
    "print(confusion_matrix(yc_test,yc_pred))\n",
    "print(classification_report(yc_test,yc_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(yc_test, yc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Trick\n",
    "\n",
    "\n",
    "References: http://www.eric-kim.net/eric-kim-net/posts/1/kernel_trick.html\n",
    "\n",
    "https://prateekvjoshi.com/2012/09/01/kernel-functions-for-machine-learning/\n",
    "\n",
    "<img src=\"kernel1.png\" width=500 height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different kernel functions\n",
    "\n",
    "References: https://www.slideshare.net/okamoto-laboratory/families-of-triangular-norm-based-kernel-function-and-its-application-to-kernel-kmeans-conference\n",
    "\n",
    "<img src=\"kernel2.png\" width=400, height=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When to use which kernel?\n",
    "\n",
    "Use linear SVM for linear problems and non-linear kernels such as RBF for non-linear data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider SVM with kernel trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "\n",
    "# Assign colum names to the dataset\n",
    "colnames = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n",
    "\n",
    "# Read dataset to pandas dataframe\n",
    "irisdata = pd.read_csv(url, names=colnames)\n",
    "\n",
    "print(irisdata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n"
     ]
    }
   ],
   "source": [
    "print(irisdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal-length  sepal-width  petal-length  petal-width        Class\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "print(irisdata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "print(irisdata['Class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisdata1 = irisdata.copy(deep=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = {'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2}\n",
    "\n",
    "#irisdata1.Class = irisdata1.Class.apply(lambda x: c[x])\n",
    "\n",
    "irisdata.Class = [c[item] for item in irisdata.Class] # list comprehension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "Name: Class, dtype: int64\n",
      "   sepal-length  sepal-width  petal-length  petal-width  Class\n",
      "0           5.1          3.5           1.4          0.2      0\n",
      "1           4.9          3.0           1.4          0.2      0\n",
      "2           4.7          3.2           1.3          0.2      0\n",
      "3           4.6          3.1           1.5          0.2      0\n",
      "4           5.0          3.6           1.4          0.2      0\n"
     ]
    }
   ],
   "source": [
    "print(irisdata.Class[0:2])\n",
    "print(irisdata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = irisdata.drop('Class', axis=1)\n",
    "y = irisdata['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links to understand $gamma,$ and degree\n",
    "\n",
    "https://scikit-learn.org/stable/modules/svm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(degree=2, gamma='auto', kernel='poly')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# polynomial kernel\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='poly', degree=2, gamma='auto')\n",
    "svclassifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma='auto')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RBF kernel\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='rbf', gamma='auto')\n",
    "svclassifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "['mean_fit_time', 'mean_score_time', 'mean_test_score', 'param_C', 'param_kernel', 'params', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'std_fit_time', 'std_score_time', 'std_test_score']\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'kernel':['linear', 'rbf', 'poly'], 'C':[1, 5, 10]}\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "clf = GridSearchCV(svc, param_grid = parameters, cv = 3, verbose=True, n_jobs=-1)\n",
    "\n",
    "final_clf = clf.fit(xc_train, yc_train)\n",
    "\n",
    "\n",
    "print(sorted(final_clf.cv_results_.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=5)\n",
      "{'C': 5, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(final_clf.best_estimator_)\n",
    "print(final_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[145   0]\n",
      " [  0 130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       145\n",
      "           1       1.00      1.00      1.00       130\n",
      "\n",
      "    accuracy                           1.00       275\n",
      "   macro avg       1.00      1.00      1.00       275\n",
      "weighted avg       1.00      1.00      1.00       275\n",
      "\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Using the best parameters from the above GridSearchCV\n",
    "# we build another svc model\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel = 'rbf', C=5)\n",
    "svc.fit(xc_train, yc_train) # fiting the data to the model\n",
    "\n",
    "svc.fit(xc_train, yc_train) # fiting the data to the model\n",
    "yc_pred = svc.predict(xc_test)\n",
    "print(confusion_matrix(yc_test,yc_pred))\n",
    "print(classification_report(yc_test,yc_pred))\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn-class activity: consider Titanic dataset and apply SVM along with GridSearchCV to determine the best parameteres \\nfor kernel and C. \\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In-class activity: consider Titanic dataset and apply SVM along with GridSearchCV to determine the best parameteres \n",
    "for kernel and C. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
