{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal is to convert categorical features into "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import make_column_selector as col_selector\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"population.csv\")\n",
    "\n",
    "#print(df.head())\n",
    "#print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'Job Type', 'Final Weight', 'Education', 'Education Number',\n",
      "       'Marital Status', 'Job Title', 'Relationship', 'Race', 'Gender',\n",
      "       'Capital Gain', 'Capital Loss', 'Hours per week', 'Country', 'Income'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "#print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " White                 27816\n",
      " Black                  3124\n",
      " Asian-Pac-Islander     1039\n",
      " Amer-Indian-Eskimo      311\n",
      " Other                   271\n",
      "Name: Race, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#print(df[\"Job Type\"].value_counts())\n",
    "#print(df[\"Country\"].value_counts())\n",
    "#print(df[\"Job Title\"].value_counts())\n",
    "#print(df[\"Marital Status\"].value_counts())\n",
    "print(df[\"Race\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Job Type\"] = df[\"Job Type\"].str.replace(\"?\", \"Other\")\n",
    "df[\"Country\"] = df[\"Country\"].str.replace(\"?\", \"Other\")\n",
    "df[\"Job Title\"] = df[\"Job Title\"].str.replace(\"?\", \"Other\")\n",
    "\n",
    "#print(df[\"Job Type\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy = df[\"Income\"]\n",
    "df = df.drop([\"Income\"], axis=1)\n",
    "df1 = df.copy(deep=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating categorical_cols and int_cols objects\n",
    "\n",
    "We use col_selector to do this. \n",
    "We also create categorical_features and numerical_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.compose._column_transformer.make_column_selector'>\n",
      "<class 'list'>\n",
      "['Job Type', 'Education', 'Marital Status', 'Job Title', 'Relationship', 'Race', 'Gender', 'Country']\n",
      "['Age', 'Final Weight', 'Education Number', 'Capital Gain', 'Capital Loss', 'Hours per week']\n"
     ]
    }
   ],
   "source": [
    "# categorical_cols_obj is a categorical object\n",
    "categorical_cols_obj = col_selector(dtype_include=object)\n",
    "print(type(categorical_cols_obj))\n",
    "\n",
    "# categorical_features is a list of  column names of features with catergorical data\n",
    "categorical_features = categorical_cols_obj(df)\n",
    "print(type(categorical_features))\n",
    "\n",
    "# numeric_features is a list of column names of features with numeric data\n",
    "int_cols_obj = col_selector(dtype_include=\"int64\")\n",
    "numeric_features = int_cols_obj(df)\n",
    "\n",
    "print(categorical_features)\n",
    "print(numeric_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating data frame with categorical_features\n",
    "\n",
    "Creating an OrdinalEncoder object and performing a fit_transform on the df_cat dataframe.\n",
    "\n",
    "In the below example, we are not scaling columns with numeric_features. \n",
    "\n",
    "We are performing hstack to put encoded categorical dataframe with the numeric dataframe.\n",
    "\n",
    "Since our target variable is categorical, we perform LabelEncoder on this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 14)\n"
     ]
    }
   ],
   "source": [
    "df_cat = df[categorical_features]\n",
    "ob_encoded = preprocessing.OrdinalEncoder()\n",
    "cat_encoded = ob_encoded.fit_transform(df_cat)\n",
    "\n",
    "x = np.hstack([cat_encoded, np.array(df[numeric_features])])\n",
    "print(x.shape)\n",
    "\n",
    "yb = preprocessing.LabelEncoder()\n",
    "y = yb.fit_transform(dfy)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas cat.codes\n",
    "\n",
    "Using Pandas cat.codes for Catgeorical feature conversion. \n",
    "Then Using StandardScaler for standarizing the numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 14)\n",
      "Accuracy: 0.8277291570704745\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Recall - we already have categorical features and numeric_features from the previous cell.\n",
    "Here it is again.\n",
    "\n",
    "\n",
    "categorical_cols_obj = col_selector(dtype_include=object)\n",
    "print(type(categorical_cols_obj))\n",
    "categorical_features = categorical_cols_obj(df)\n",
    "print(type(categorical_features))\n",
    "\n",
    "int_cols_obj = col_selector(dtype_include=\"int64\")\n",
    "numeric_features = int_cols_obj(df)\n",
    "\n",
    "print(categorical_features)\n",
    "print(numeric_features)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "for i in range(len(categorical_features)):\n",
    "    df1[categorical_features[i]] = df1[categorical_features[i]].astype('category')\n",
    "    df1[categorical_features[i]] = df1[categorical_features[i]].cat.codes\n",
    "\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "x = np.hstack([df1[categorical_features], sc.fit_transform(df1[numeric_features])])\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Recall\n",
    "\n",
    "our y is \n",
    "\n",
    "yb = preprocessing.LabelEncoder()\n",
    "y = yb.fit_transform(dfy)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                   x, y, test_size = 0.2, random_state=1)\n",
    "\n",
    "clf = LogisticRegression(max_iter=500)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Standard Scaler and make_pipeline\n",
    "\n",
    "Performing StandardScaler only on numeric columns and then using \n",
    "make_pipeline.\n",
    "\n",
    "Syntax for make_pipeline(list of estimator objects, model)\n",
    "\n",
    "The numeric columns in our dataset are:\n",
    "'Age', 'Final Weight', 'Education Number', 'Capital Gain', 'Capital Loss', 'Hours per week'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8182097343773991\n"
     ]
    }
   ],
   "source": [
    "lst = ['Age', 'Final Weight', 'Education Number', 'Capital Gain', \n",
    "       'Capital Loss', 'Hours per week']\n",
    "\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "    train_test_split(df[lst], y, test_size = 0.2, random_state=1)\n",
    "\n",
    "\n",
    "st = StandardScaler()\n",
    "\n",
    "\"\"\"\n",
    "Example of Pipeline. Here we have to give the name of the estimator as a string \n",
    "followed by the estimator. \n",
    "In make_pipeline, we can just provide the list of estimators. \n",
    "\n",
    "\n",
    "clf = Pipeline([('preprocessor', preprocessor),\n",
    "                  ('classifier', LogisticRegression(max_iter=500))])\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "mpipe = make_pipeline(st, LogisticRegression())\n",
    "\n",
    "mpipe.fit(x_train, y_train)\n",
    "\n",
    "ym_pred = mpipe.predict(x_test)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, ym_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Transform  \n",
    "\n",
    "#### Encoding using Oridnal and scaling the numeric columns\n",
    "\n",
    "Performing StandardScaler and OrdinalEncoder \n",
    "on numeric columns and categorical columns respectively and \n",
    "then using make_pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.818\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "X = df\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "               transformers=[\n",
    "               ('num', StandardScaler(), numeric_features),\n",
    "               ('cat', OrdinalEncoder(), categorical_features)])\n",
    "\n",
    "#clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "#                      ('classifier', LogisticRegression())])\n",
    "\n",
    "clf = make_pipeline(preprocessor, LogisticRegression(max_iter=500))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHotEncoder\n",
    "\n",
    "\n",
    "Performing StandardScaler and OneHotEncoder \n",
    "on numeric columns and categorical columns respectively and \n",
    "then using make_pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 14)\n",
      "model score: 0.847\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "X = df\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "               transformers=[\n",
    "               ('num', StandardScaler(), numeric_features),\n",
    "               ('cat', OneHotEncoder(), categorical_features)])\n",
    "\n",
    "\n",
    "#clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "#                      ('classifier', LogisticRegression())])\n",
    "\n",
    "clf = make_pipeline(preprocessor, LogisticRegression(max_iter=500))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
